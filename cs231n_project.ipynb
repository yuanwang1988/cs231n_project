{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cs231n_project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Tmnas7RKjGmZ6IRX4ln82U4nNYO3KBzU",
      "authorship_tag": "ABX9TyPO95Rg3x1V5sBu183YEzno",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuanwang1988/cs231n_project/blob/master/cs231n_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2CREMnXvezl",
        "colab_type": "text"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sE8OTRQPtiht",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Imports\n",
        "%matplotlib inline\n",
        "import numpy as np                   # advanced math library\n",
        "import matplotlib.pyplot as plt      # MATLAB like plotting routines\n",
        "import os\n",
        "import random                        # for generating random numbers\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential, Model  # Model type to be used\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation # Types of layers to be used in our model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, Flatten, BatchNormalization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGOgiNXYz97F",
        "colab_type": "code",
        "outputId": "706870e5-e1cd-4cf8-e9bc-7f7e32a2186c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!pip install pyyaml h5py  # Required to save models in HDF5 format"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (2.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py) (1.18.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rRmLaw0yiPD",
        "colab_type": "code",
        "outputId": "3850088b-ef6b-4917-f960-2cb0249096a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(tf.version.VERSION)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOOcDd9K9uVq",
        "colab_type": "code",
        "outputId": "45af1073-04ca-41d6-dd4b-3bfaa4289027",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "output_dir = F\"/content/gdrive/My Drive/cs231n_project/\" "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIqy3m_Gvlvu",
        "colab_type": "text"
      },
      "source": [
        "# Data Processing Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79wBdFqB6unn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_class_distribution(labels):\n",
        "  (unique, counts) = np.unique(labels, return_counts=True)\n",
        "  for v, c in zip(unique, counts):\n",
        "    print('{}: {}'.format(v,c))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNJCEasC21gj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_transfer_learning_data(\n",
        "    X_train, y_train, X_test, y_test,\n",
        "    source_task_classes, target_task_classes):\n",
        "  \n",
        "  X_train_src = X_train[np.isin(y_train, source_task_classes)]\n",
        "  y_train_src = y_train[np.isin(y_train, source_task_classes)]\n",
        "  \n",
        "  X_test_src = X_test[np.isin(y_test, source_task_classes)]\n",
        "  y_test_src = y_test[np.isin(y_test, source_task_classes)]\n",
        "\n",
        "  X_train_tgt = X_train[np.isin(y_train, target_task_classes)]\n",
        "  y_train_tgt = y_train[np.isin(y_train, target_task_classes)]\n",
        "  \n",
        "  X_test_tgt = X_test[np.isin(y_test, target_task_classes)]\n",
        "  y_test_tgt = y_test[np.isin(y_test, target_task_classes)]\n",
        "\n",
        "  return (X_train_src, y_train_src, X_test_src, y_test_src, \n",
        "          X_train_tgt, y_train_tgt, X_test_tgt, y_test_tgt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hm9E1pnDa363",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def shuffle_dataset(X, y):\n",
        "  assert len(X) == len(y)\n",
        "  shuffle_order = np.random.permutation(len(X))\n",
        "  return X[shuffle_order], y[shuffle_order]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWb9HA-PYoB9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def subsample_train_data(X_train, y_train, n_samples_per_class):\n",
        "  X_train_subsamples = []\n",
        "  y_train_subsamples = []\n",
        "  for label in np.unique(y_train):\n",
        "    mask = (y_train==label)\n",
        "    n_examples = len(y_train[mask])\n",
        "    X_train_subsamples.append(X_train[mask][:min(n_examples, n_samples_per_class)])\n",
        "    y_train_subsamples.append(y_train[mask][:min(n_examples, n_samples_per_class)])\n",
        "    \n",
        "  X_train_sample = np.concatenate(X_train_subsamples)\n",
        "  y_train_sample = np.concatenate(y_train_subsamples)\n",
        "\n",
        "  return X_train_sample, y_train_sample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POzA1sS5FxnL",
        "colab_type": "text"
      },
      "source": [
        "# Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xZ-rh02FxIe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_accuracy_results(accuracy_results):\n",
        "  print('num examples per class: accuracy')\n",
        "  for n, acc in accuracy_results.items():\n",
        "    print('{}: {:.4f}'.format(n, acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFbqtI2TtC6V",
        "colab_type": "text"
      },
      "source": [
        "# MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjZEqJaHuCmI",
        "colab_type": "text"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDUX5es-s924",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import mnist     # MNIST dataset is included in Keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfAR-rg1t3aQ",
        "colab_type": "code",
        "outputId": "ddbc27d9-4aab-4d97-a8f1-0c41d027dc06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# The MNIST data is split between 60,000 28 x 28 pixel training images and 10,000 28 x 28 pixel images\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "print(\"X_train shape\", X_train.shape)\n",
        "print(\"y_train shape\", y_train.shape)\n",
        "print(\"X_test shape\", X_test.shape)\n",
        "print(\"y_test shape\", y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n",
            "X_train shape (60000, 28, 28)\n",
            "y_train shape (60000,)\n",
            "X_test shape (10000, 28, 28)\n",
            "y_test shape (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMHKaguZwef5",
        "colab_type": "text"
      },
      "source": [
        "## Create Transfer Learning Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XJTh59awici",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "source_task_classes = [0,1,2,3,4]\n",
        "target_task_classes = [5,6,7,8,9]\n",
        "n_examples_per_class_list = [1, 5, 10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ubzbe9HNwlUQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = create_transfer_learning_data(X_train, y_train, X_test, y_test, source_task_classes, target_task_classes)\n",
        "X_train_src, y_train_src, X_test_src, y_test_src, X_train_tgt, y_train_tgt, X_test_tgt, y_test_tgt = dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NO08Px4Mw46W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_tgt, y_train_tgt = shuffle_dataset(X_train_tgt, y_train_tgt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzCzrGRt7Ktw",
        "colab_type": "code",
        "outputId": "1e3d2801-beab-4718-e5fb-d8de1377a0e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print_class_distribution(y_train_src)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0: 5923\n",
            "1: 6742\n",
            "2: 5958\n",
            "3: 6131\n",
            "4: 5842\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMvQ5S9b7XyV",
        "colab_type": "code",
        "outputId": "61dc4a12-b11d-400e-de63-b372e3e02c0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print_class_distribution(y_test_src)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0: 980\n",
            "1: 1135\n",
            "2: 1032\n",
            "3: 1010\n",
            "4: 982\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yr1xD8Tu9Zk6",
        "colab_type": "code",
        "outputId": "ef7dc8b4-12dc-426a-f663-8fc4251ce70a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print_class_distribution(y_train_tgt)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5: 5421\n",
            "6: 5918\n",
            "7: 6265\n",
            "8: 5851\n",
            "9: 5949\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDqgRXgN9b5n",
        "colab_type": "code",
        "outputId": "76b5334a-9a94-46d8-8c6c-d665dcc84d88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print_class_distribution(y_test_tgt)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5: 892\n",
            "6: 958\n",
            "7: 1028\n",
            "8: 974\n",
            "9: 1009\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfKi4n9SwKSe",
        "colab_type": "text"
      },
      "source": [
        "## Fully Connected DNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCSjUVSF9xfK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_data_fc_model(X, y, label_map=None):\n",
        "  X = X.reshape(X.shape[0], -1) # reshape 60,000 28 x 28 matrices into 60,000 784-length vectors.\n",
        "  X = X.astype('float32')\n",
        "  X /= 255\n",
        "\n",
        "  if label_map is None:\n",
        "    label_map = {}\n",
        "    class_labels = np.unique(y)\n",
        "    for i in range(len(class_labels)):\n",
        "      label_map[class_labels[i]] = i\n",
        "\n",
        "  def map_label(label):\n",
        "    return label_map[label]\n",
        "\n",
        "  nb_classes = len(np.unique(y))\n",
        "  y = np.vectorize(map_label)(y)\n",
        "  y = np_utils.to_categorical(y, nb_classes)\n",
        "\n",
        "  return X, y, label_map"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rywO9BtCt6Ce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_simple_fc_model(\n",
        "    input_shape,\n",
        "    num_classes,\n",
        "    hidden_layer_dims,\n",
        "    drop_out_prob):\n",
        "  model = Sequential(\n",
        "      layers=[Dense(hidden_layer_dims[0], input_shape=input_shape, activation='relu', name='fc_1'),\n",
        "              Dropout(drop_out_prob),\n",
        "              Dense(hidden_layer_dims[1], activation='relu', name='fc_2'),\n",
        "              Dropout(drop_out_prob),\n",
        "              Dense(num_classes, name = 'fc_3'),\n",
        "              Activation('softmax')\n",
        "      ],\n",
        "      name = 'FC1')\n",
        "  \n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1JT0IL_BJDZ",
        "colab_type": "text"
      },
      "source": [
        "### Sanity Check (Train and Eval on the Entire Target Training Set)\n",
        "\n",
        "This checks whether the model architecture is good given large amount of training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-968H5csBO_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = create_simple_fc_model(\n",
        "    input_shape=(784,),\n",
        "    num_classes=len(target_task_classes),\n",
        "    hidden_layer_dims=[512,512],\n",
        "    drop_out_prob=0.2\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6oNYo2ABZfI",
        "colab_type": "code",
        "outputId": "f1309a7c-1be1-42c0-f782-086bcbabccc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"FC1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "fc_1 (Dense)                 (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "fc_2 (Dense)                 (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "fc_3 (Dense)                 (None, 5)                 2565      \n",
            "_________________________________________________________________\n",
            "activation_30 (Activation)   (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 667,141\n",
            "Trainable params: 667,141\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjq7m75iBiUN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_tgt_sample, y_train_tgt_sample = subsample_train_data(X_train_tgt[:-1000], y_train_tgt[:-1000], 10000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-Ro2-oDBr-Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_tgt_fc_sample, y_train_tgt_fc_sample, label_map = preprocess_data_fc_model(X_train_tgt_sample, y_train_tgt_sample)\n",
        "X_valid_tgt_fc, y_valid_tgt_fc, label_map = preprocess_data_fc_model(X_train_tgt[1000:], y_train_tgt[1000:], label_map)\n",
        "X_test_tgt_fc, y_test_tgt_fc, label_map = preprocess_data_fc_model(X_test_tgt, y_test_tgt, label_map)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1HaKKAiBuiu",
        "colab_type": "code",
        "outputId": "ad274de3-a037-4e1a-8166-d96118f728c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print_class_distribution(y_train_tgt_sample)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5: 5255\n",
            "6: 5734\n",
            "7: 6040\n",
            "8: 5646\n",
            "9: 5729\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y13XqYwKBv5M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_path = output_dir+\"mnist_fc_sanity_check/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create a callback that saves the model's weights\n",
        "cp_callback = ModelCheckpoint(filepath=checkpoint_path,\n",
        "                              verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tid7aqhaCKz3",
        "colab_type": "code",
        "outputId": "93c48708-c0bd-4da3-fb2a-588724fd6a7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        }
      },
      "source": [
        "model.fit(X_train_tgt_fc_sample, y_train_tgt_fc_sample,\n",
        "          batch_size=128, \n",
        "          epochs=10,\n",
        "          verbose=1,\n",
        "          validation_data=(X_valid_tgt_fc, y_valid_tgt_fc),\n",
        "          callbacks=[cp_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "219/222 [============================>.] - ETA: 0s - loss: 0.0682 - accuracy: 0.9781\n",
            "Epoch 00001: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_sanity_check/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_sanity_check/cp.ckpt/assets\n",
            "222/222 [==============================] - 2s 10ms/step - loss: 0.0682 - accuracy: 0.9780 - val_loss: 0.0326 - val_accuracy: 0.9908\n",
            "Epoch 2/10\n",
            "217/222 [============================>.] - ETA: 0s - loss: 0.0407 - accuracy: 0.9859\n",
            "Epoch 00002: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_sanity_check/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_sanity_check/cp.ckpt/assets\n",
            "222/222 [==============================] - 2s 10ms/step - loss: 0.0403 - accuracy: 0.9860 - val_loss: 0.0224 - val_accuracy: 0.9926\n",
            "Epoch 3/10\n",
            "219/222 [============================>.] - ETA: 0s - loss: 0.0330 - accuracy: 0.9889\n",
            "Epoch 00003: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_sanity_check/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_sanity_check/cp.ckpt/assets\n",
            "222/222 [==============================] - 2s 11ms/step - loss: 0.0337 - accuracy: 0.9887 - val_loss: 0.0177 - val_accuracy: 0.9944\n",
            "Epoch 4/10\n",
            "220/222 [============================>.] - ETA: 0s - loss: 0.0265 - accuracy: 0.9910\n",
            "Epoch 00004: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_sanity_check/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_sanity_check/cp.ckpt/assets\n",
            "222/222 [==============================] - 2s 10ms/step - loss: 0.0268 - accuracy: 0.9910 - val_loss: 0.0107 - val_accuracy: 0.9967\n",
            "Epoch 5/10\n",
            "216/222 [============================>.] - ETA: 0s - loss: 0.0192 - accuracy: 0.9939\n",
            "Epoch 00005: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_sanity_check/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_sanity_check/cp.ckpt/assets\n",
            "222/222 [==============================] - 3s 12ms/step - loss: 0.0198 - accuracy: 0.9937 - val_loss: 0.0144 - val_accuracy: 0.9955\n",
            "Epoch 6/10\n",
            "208/222 [===========================>..] - ETA: 0s - loss: 0.0168 - accuracy: 0.9943\n",
            "Epoch 00006: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_sanity_check/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_sanity_check/cp.ckpt/assets\n",
            "222/222 [==============================] - 2s 10ms/step - loss: 0.0171 - accuracy: 0.9942 - val_loss: 0.0128 - val_accuracy: 0.9958\n",
            "Epoch 7/10\n",
            "218/222 [============================>.] - ETA: 0s - loss: 0.0171 - accuracy: 0.9937\n",
            "Epoch 00007: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_sanity_check/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_sanity_check/cp.ckpt/assets\n",
            "222/222 [==============================] - 2s 10ms/step - loss: 0.0169 - accuracy: 0.9938 - val_loss: 0.0109 - val_accuracy: 0.9965\n",
            "Epoch 8/10\n",
            "218/222 [============================>.] - ETA: 0s - loss: 0.0178 - accuracy: 0.9940\n",
            "Epoch 00008: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_sanity_check/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_sanity_check/cp.ckpt/assets\n",
            "222/222 [==============================] - 2s 10ms/step - loss: 0.0180 - accuracy: 0.9940 - val_loss: 0.0069 - val_accuracy: 0.9981\n",
            "Epoch 9/10\n",
            "219/222 [============================>.] - ETA: 0s - loss: 0.0117 - accuracy: 0.9960\n",
            "Epoch 00009: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_sanity_check/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_sanity_check/cp.ckpt/assets\n",
            "222/222 [==============================] - 2s 10ms/step - loss: 0.0116 - accuracy: 0.9961 - val_loss: 0.0046 - val_accuracy: 0.9987\n",
            "Epoch 10/10\n",
            "219/222 [============================>.] - ETA: 0s - loss: 0.0122 - accuracy: 0.9960\n",
            "Epoch 00010: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_sanity_check/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_sanity_check/cp.ckpt/assets\n",
            "222/222 [==============================] - 2s 10ms/step - loss: 0.0125 - accuracy: 0.9959 - val_loss: 0.0069 - val_accuracy: 0.9980\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f59c747dcf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9-Bw5wUCwv5",
        "colab_type": "code",
        "outputId": "f08d9b64-ba27-4faa-96dd-4273de5acb4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "score = model.evaluate(X_test_tgt_fc, y_test_tgt_fc)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "152/152 [==============================] - 0s 3ms/step - loss: 0.0583 - accuracy: 0.9862\n",
            "Test score: 0.05829891562461853\n",
            "Test accuracy: 0.9862168431282043\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBlx3MlJjmP1",
        "colab_type": "text"
      },
      "source": [
        "### Baseline No Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pocyLAQC85I",
        "colab_type": "code",
        "outputId": "0d31f05a-a69e-441b-ba87-b28b719c254c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "test_accuracy_results = {}\n",
        "\n",
        "for n_examples_per_class in n_examples_per_class_list:\n",
        "  X_train_tgt_sample, y_train_tgt_sample = subsample_train_data(X_train_tgt[:-1000], y_train_tgt[:-1000], n_examples_per_class)\n",
        "  assert len(y_train_tgt_sample) <= n_examples_per_class * len(np.unique(y_train_tgt))\n",
        "  \n",
        "  X_train_tgt_fc_sample, y_train_tgt_fc_sample, label_map = preprocess_data_fc_model(X_train_tgt_sample, y_train_tgt_sample)\n",
        "  X_valid_tgt_fc, y_valid_tgt_fc, label_map = preprocess_data_fc_model(X_train_tgt[1000:], y_train_tgt[1000:], label_map)\n",
        "  X_test_tgt_fc, y_test_tgt_fc, label_map = preprocess_data_fc_model(X_test_tgt, y_test_tgt, label_map)\n",
        "\n",
        "  model = create_simple_fc_model(\n",
        "    input_shape=(784,),\n",
        "    num_classes=len(target_task_classes),\n",
        "    hidden_layer_dims=[512,512],\n",
        "    drop_out_prob=0.2\n",
        "  )\n",
        "  # checkpoint_path = \"cs231n/project/model_checkpoints/minist_fc_test/cp.ckpt\"\n",
        "  checkpoint_path = output_dir+\"mnist_fc_no_tl_{}_samples_per_class/cp.ckpt\".format(n_examples_per_class)\n",
        "  checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "  # Create a callback that saves the model's weights\n",
        "  cp_callback = ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                verbose=1)\n",
        "  model.fit(X_train_tgt_fc_sample, y_train_tgt_fc_sample,\n",
        "          batch_size=128, \n",
        "          epochs=10,\n",
        "          verbose=1,\n",
        "          validation_data=(X_valid_tgt_fc, y_valid_tgt_fc),\n",
        "          callbacks=[cp_callback])\n",
        "  \n",
        "  score = model.evaluate(X_test_tgt_fc, y_test_tgt_fc)\n",
        "  print('+++++++++++++++++++++++++++++++++++')\n",
        "  print('num examples per class', n_examples_per_class)\n",
        "  print('Test score:', score[0])\n",
        "  print('Test accuracy:', score[1])\n",
        "  print('+++++++++++++++++++++++++++++++++++')\n",
        "  test_accuracy_results[n_examples_per_class] = score[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.6032 - accuracy: 0.2000\n",
            "Epoch 00001: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_1_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_1_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.6032 - accuracy: 0.2000 - val_loss: 1.5635 - val_accuracy: 0.2582\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.2104 - accuracy: 1.0000\n",
            "Epoch 00002: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_1_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_1_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 3s 3s/step - loss: 1.2104 - accuracy: 1.0000 - val_loss: 1.4728 - val_accuracy: 0.4316\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7510 - accuracy: 1.0000\n",
            "Epoch 00003: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_1_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_1_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.7510 - accuracy: 1.0000 - val_loss: 1.3952 - val_accuracy: 0.4885\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3755 - accuracy: 1.0000\n",
            "Epoch 00004: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_1_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_1_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3755 - accuracy: 1.0000 - val_loss: 1.3291 - val_accuracy: 0.5071\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2259 - accuracy: 1.0000\n",
            "Epoch 00005: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_1_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_1_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2259 - accuracy: 1.0000 - val_loss: 1.2743 - val_accuracy: 0.5186\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1461 - accuracy: 1.0000\n",
            "Epoch 00006: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_1_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_1_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1461 - accuracy: 1.0000 - val_loss: 1.2282 - val_accuracy: 0.5320\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0517 - accuracy: 1.0000\n",
            "Epoch 00007: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_1_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_1_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0517 - accuracy: 1.0000 - val_loss: 1.1955 - val_accuracy: 0.5422\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0468 - accuracy: 1.0000\n",
            "Epoch 00008: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_1_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_1_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0468 - accuracy: 1.0000 - val_loss: 1.1736 - val_accuracy: 0.5494\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0132 - accuracy: 1.0000\n",
            "Epoch 00009: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_1_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_1_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 1.1628 - val_accuracy: 0.5550\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 1.0000\n",
            "Epoch 00010: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_1_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_1_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 1.1610 - val_accuracy: 0.5598\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.1675 - accuracy: 0.5565\n",
            "+++++++++++++++++++++++++++++++++++\n",
            "num examples per class 1\n",
            "Test score: 1.1674911975860596\n",
            "Test accuracy: 0.5564698576927185\n",
            "+++++++++++++++++++++++++++++++++++\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.7544 - accuracy: 0.1200\n",
            "Epoch 00001: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_5_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_5_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.7544 - accuracy: 0.1200 - val_loss: 1.4748 - val_accuracy: 0.3634\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.3321 - accuracy: 0.5600\n",
            "Epoch 00002: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_5_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_5_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.3321 - accuracy: 0.5600 - val_loss: 1.3624 - val_accuracy: 0.5246\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.0192 - accuracy: 0.9200\n",
            "Epoch 00003: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_5_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_5_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.0192 - accuracy: 0.9200 - val_loss: 1.2484 - val_accuracy: 0.6259\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7798 - accuracy: 0.9200\n",
            "Epoch 00004: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_5_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_5_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.7798 - accuracy: 0.9200 - val_loss: 1.1300 - val_accuracy: 0.6714\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5214 - accuracy: 0.9600\n",
            "Epoch 00005: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_5_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_5_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.5214 - accuracy: 0.9600 - val_loss: 1.0131 - val_accuracy: 0.7077\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3484 - accuracy: 1.0000\n",
            "Epoch 00006: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_5_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_5_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3484 - accuracy: 1.0000 - val_loss: 0.9129 - val_accuracy: 0.7254\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2352 - accuracy: 1.0000\n",
            "Epoch 00007: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_5_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_5_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2352 - accuracy: 1.0000 - val_loss: 0.8402 - val_accuracy: 0.7312\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1311 - accuracy: 1.0000\n",
            "Epoch 00008: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_5_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_5_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1311 - accuracy: 1.0000 - val_loss: 0.7947 - val_accuracy: 0.7301\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0846 - accuracy: 1.0000\n",
            "Epoch 00009: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_5_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_5_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0846 - accuracy: 1.0000 - val_loss: 0.7681 - val_accuracy: 0.7307\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0527 - accuracy: 1.0000\n",
            "Epoch 00010: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_5_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_5_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0527 - accuracy: 1.0000 - val_loss: 0.7540 - val_accuracy: 0.7332\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.7194 - accuracy: 0.7484\n",
            "+++++++++++++++++++++++++++++++++++\n",
            "num examples per class 5\n",
            "Test score: 0.719373881816864\n",
            "Test accuracy: 0.7484056949615479\n",
            "+++++++++++++++++++++++++++++++++++\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.7451 - accuracy: 0.1600\n",
            "Epoch 00001: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_10_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_10_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.7451 - accuracy: 0.1600 - val_loss: 1.4154 - val_accuracy: 0.5722\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.2820 - accuracy: 0.6000\n",
            "Epoch 00002: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_10_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_10_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.2820 - accuracy: 0.6000 - val_loss: 1.2804 - val_accuracy: 0.6132\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.0054 - accuracy: 0.7800\n",
            "Epoch 00003: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_10_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_10_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.0054 - accuracy: 0.7800 - val_loss: 1.1394 - val_accuracy: 0.6388\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8274 - accuracy: 0.8600\n",
            "Epoch 00004: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_10_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_10_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.8274 - accuracy: 0.8600 - val_loss: 0.9802 - val_accuracy: 0.7238\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6016 - accuracy: 0.9400\n",
            "Epoch 00005: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_10_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_10_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6016 - accuracy: 0.9400 - val_loss: 0.8317 - val_accuracy: 0.7860\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4229 - accuracy: 0.9800\n",
            "Epoch 00006: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_10_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_10_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.4229 - accuracy: 0.9800 - val_loss: 0.7230 - val_accuracy: 0.8051\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3025 - accuracy: 0.9800\n",
            "Epoch 00007: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_10_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_10_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3025 - accuracy: 0.9800 - val_loss: 0.6555 - val_accuracy: 0.8046\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2016 - accuracy: 1.0000\n",
            "Epoch 00008: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_10_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_10_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2016 - accuracy: 1.0000 - val_loss: 0.6063 - val_accuracy: 0.8053\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1540 - accuracy: 1.0000\n",
            "Epoch 00009: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_10_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_10_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1540 - accuracy: 1.0000 - val_loss: 0.5681 - val_accuracy: 0.8104\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0883 - accuracy: 1.0000\n",
            "Epoch 00010: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_10_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_no_tl_10_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0883 - accuracy: 1.0000 - val_loss: 0.5469 - val_accuracy: 0.8119\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.5212 - accuracy: 0.8177\n",
            "+++++++++++++++++++++++++++++++++++\n",
            "num examples per class 10\n",
            "Test score: 0.521176278591156\n",
            "Test accuracy: 0.8177329897880554\n",
            "+++++++++++++++++++++++++++++++++++\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c04FqD6ZGLTq",
        "colab_type": "code",
        "outputId": "ac5a777d-59e1-44dd-ee54-ec2077c99f79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print_accuracy_results(test_accuracy_results)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num examples per class: accuracy\n",
            "1: 0.5565\n",
            "5: 0.7484\n",
            "10: 0.8177\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFq1ob7Ljgpz",
        "colab_type": "text"
      },
      "source": [
        "### With Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDM7bTP0jf6d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_src_fc, y_train_src_fc, label_map = preprocess_data_fc_model(X_train_src, y_train_src)\n",
        "X_test_src_fc, y_test_src_fc, label_map = preprocess_data_fc_model(X_test_src, y_test_src, label_map)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AAxbut0j03G",
        "colab_type": "code",
        "outputId": "a2463054-35d1-4479-ca6e-a63b880fecd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "label_map"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HblcyFAXi5pg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pre_trained_model = create_simple_fc_model(\n",
        "    input_shape=(784,),\n",
        "    num_classes=len(target_task_classes),\n",
        "    hidden_layer_dims=[512,512],\n",
        "    drop_out_prob=0.2\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qU280NijItX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_path = output_dir+\"mnist_fc_tl_pretrained_model/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create a callback that saves the model's weights\n",
        "cp_callback = ModelCheckpoint(filepath=checkpoint_path,\n",
        "                              verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBpmFXhDjLKY",
        "colab_type": "code",
        "outputId": "5be55035-98c6-4fec-ff61-8e126ae942af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        }
      },
      "source": [
        "pre_trained_model.fit(X_train_src_fc[:-1000], y_train_src_fc[:-1000],\n",
        "          batch_size=128, \n",
        "          epochs=10,\n",
        "          verbose=1,\n",
        "          validation_data=(X_train_src_fc[1000:], y_train_src_fc[1000:]),\n",
        "          callbacks=[cp_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "221/232 [===========================>..] - ETA: 0s - loss: 0.1251 - accuracy: 0.9616\n",
            "Epoch 00001: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_pretrained_model/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_pretrained_model/cp.ckpt/assets\n",
            "232/232 [==============================] - 2s 10ms/step - loss: 0.1220 - accuracy: 0.9625 - val_loss: 0.0405 - val_accuracy: 0.9875\n",
            "Epoch 2/10\n",
            "226/232 [============================>.] - ETA: 0s - loss: 0.0418 - accuracy: 0.9870\n",
            "Epoch 00002: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_pretrained_model/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_pretrained_model/cp.ckpt/assets\n",
            "232/232 [==============================] - 2s 10ms/step - loss: 0.0417 - accuracy: 0.9870 - val_loss: 0.0311 - val_accuracy: 0.9894\n",
            "Epoch 3/10\n",
            "219/232 [===========================>..] - ETA: 0s - loss: 0.0243 - accuracy: 0.9923\n",
            "Epoch 00003: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_pretrained_model/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_pretrained_model/cp.ckpt/assets\n",
            "232/232 [==============================] - 2s 10ms/step - loss: 0.0239 - accuracy: 0.9923 - val_loss: 0.0152 - val_accuracy: 0.9957\n",
            "Epoch 4/10\n",
            "229/232 [============================>.] - ETA: 0s - loss: 0.0196 - accuracy: 0.9943\n",
            "Epoch 00004: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_pretrained_model/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_pretrained_model/cp.ckpt/assets\n",
            "232/232 [==============================] - 2s 10ms/step - loss: 0.0196 - accuracy: 0.9943 - val_loss: 0.0137 - val_accuracy: 0.9954\n",
            "Epoch 5/10\n",
            "225/232 [============================>.] - ETA: 0s - loss: 0.0145 - accuracy: 0.9952\n",
            "Epoch 00005: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_pretrained_model/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_pretrained_model/cp.ckpt/assets\n",
            "232/232 [==============================] - 2s 10ms/step - loss: 0.0145 - accuracy: 0.9953 - val_loss: 0.0175 - val_accuracy: 0.9944\n",
            "Epoch 6/10\n",
            "220/232 [===========================>..] - ETA: 0s - loss: 0.0133 - accuracy: 0.9954\n",
            "Epoch 00006: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_pretrained_model/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_pretrained_model/cp.ckpt/assets\n",
            "232/232 [==============================] - 2s 10ms/step - loss: 0.0133 - accuracy: 0.9954 - val_loss: 0.0049 - val_accuracy: 0.9985\n",
            "Epoch 7/10\n",
            "218/232 [===========================>..] - ETA: 0s - loss: 0.0074 - accuracy: 0.9972\n",
            "Epoch 00007: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_pretrained_model/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_pretrained_model/cp.ckpt/assets\n",
            "232/232 [==============================] - 2s 10ms/step - loss: 0.0086 - accuracy: 0.9969 - val_loss: 0.0058 - val_accuracy: 0.9983\n",
            "Epoch 8/10\n",
            "218/232 [===========================>..] - ETA: 0s - loss: 0.0101 - accuracy: 0.9964\n",
            "Epoch 00008: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_pretrained_model/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_pretrained_model/cp.ckpt/assets\n",
            "232/232 [==============================] - 2s 9ms/step - loss: 0.0100 - accuracy: 0.9965 - val_loss: 0.0049 - val_accuracy: 0.9987\n",
            "Epoch 9/10\n",
            "218/232 [===========================>..] - ETA: 0s - loss: 0.0096 - accuracy: 0.9963\n",
            "Epoch 00009: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_pretrained_model/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_pretrained_model/cp.ckpt/assets\n",
            "232/232 [==============================] - 2s 10ms/step - loss: 0.0096 - accuracy: 0.9964 - val_loss: 0.0054 - val_accuracy: 0.9981\n",
            "Epoch 10/10\n",
            "232/232 [==============================] - ETA: 0s - loss: 0.0076 - accuracy: 0.9974\n",
            "Epoch 00010: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_pretrained_model/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_pretrained_model/cp.ckpt/assets\n",
            "232/232 [==============================] - 2s 9ms/step - loss: 0.0076 - accuracy: 0.9974 - val_loss: 0.0031 - val_accuracy: 0.9993\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f59c3de1e48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXoLxPVTnfoh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pre_trained_model = tf.keras.models.load_model(output_dir+\"mnist_fc_tl_pretrained_model/cp.ckpt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjiMe0eRjVfI",
        "colab_type": "code",
        "outputId": "7f948f58-b4a4-4cfb-f996-790877ad73c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "score = pre_trained_model.evaluate(X_test_src_fc, y_test_src_fc)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "161/161 [==============================] - 0s 3ms/step - loss: 0.0214 - accuracy: 0.9946\n",
            "Test score: 0.021421929821372032\n",
            "Test accuracy: 0.9945514798164368\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Se-RFbGoU1gT",
        "colab_type": "code",
        "outputId": "697b641b-6bba-4fa3-e2f0-0ede57cc79ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "score = pre_trained_model.evaluate(X_test_tgt_fc, y_test_tgt_fc)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "152/152 [==============================] - 0s 3ms/step - loss: 6.2780 - accuracy: 0.3750\n",
            "Test score: 6.277988910675049\n",
            "Test accuracy: 0.3750257194042206\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOI-ILu5HUjG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_fine_tune_model(\n",
        "    pre_trained_model,\n",
        "    num_classes):\n",
        "  pre_trained_model.layers[0].trainable=False\n",
        "  output = Dense(num_classes)(pre_trained_model.layers[-3].output)\n",
        "  output = Activation('softmax')(output)\n",
        "\n",
        "  fine_tune_model = Model(inputs=pre_trained_model.inputs, outputs=output)\n",
        "  fine_tune_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  return fine_tune_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0FQ7jO2kQZQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fine_tune_model = create_fine_tune_model(\n",
        "    pre_trained_model,\n",
        "    num_classes=5\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SO_HXFk4mkWd",
        "colab_type": "code",
        "outputId": "bfd068d6-a95c-4916-f28a-6c703dd6e45f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "fine_tune_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "fc_1 (Dense)                 (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "fc_2 (Dense)                 (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 5)                 2565      \n",
            "_________________________________________________________________\n",
            "activation_36 (Activation)   (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 667,141\n",
            "Trainable params: 265,221\n",
            "Non-trainable params: 401,920\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19Gqt1CGIXjf",
        "colab_type": "code",
        "outputId": "8ceee6d2-7b5e-47fd-84c0-10d0d85c4546",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "test_accuracy_results = {}\n",
        "\n",
        "for n_examples_per_class in n_examples_per_class_list:\n",
        "  X_train_tgt_sample, y_train_tgt_sample = subsample_train_data(X_train_tgt[:-1000], y_train_tgt[:-1000], n_examples_per_class)\n",
        "  assert len(y_train_tgt_sample) <= n_examples_per_class * len(np.unique(y_train_tgt))\n",
        "  \n",
        "  X_train_tgt_fc_sample, y_train_tgt_fc_sample, label_map = preprocess_data_fc_model(X_train_tgt_sample, y_train_tgt_sample)\n",
        "  X_valid_tgt_fc, y_valid_tgt_fc, label_map = preprocess_data_fc_model(X_train_tgt[1000:], y_train_tgt[1000:], label_map)\n",
        "  X_test_tgt_fc, y_test_tgt_fc, label_map = preprocess_data_fc_model(X_test_tgt, y_test_tgt, label_map)\n",
        "\n",
        "  model = create_fine_tune_model(\n",
        "    pre_trained_model,\n",
        "    num_classes=5)\n",
        "  \n",
        "  # checkpoint_path = \"cs231n/project/model_checkpoints/minist_fc_test/cp.ckpt\"\n",
        "  checkpoint_path = output_dir+\"mnist_fc_tl_{}_samples_per_class/cp.ckpt\".format(n_examples_per_class)\n",
        "  checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "  # Create a callback that saves the model's weights\n",
        "  cp_callback = ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                verbose=1)\n",
        "  model.fit(X_train_tgt_fc_sample, y_train_tgt_fc_sample,\n",
        "          batch_size=128, \n",
        "          epochs=10,\n",
        "          verbose=1,\n",
        "          validation_data=(X_valid_tgt_fc, y_valid_tgt_fc),\n",
        "          callbacks=[cp_callback])\n",
        "  \n",
        "  score = model.evaluate(X_test_tgt_fc, y_test_tgt_fc)\n",
        "  print('+++++++++++++++++++++++++++++++++++')\n",
        "  print('num examples per class', n_examples_per_class)\n",
        "  print('Test score:', score[0])\n",
        "  print('Test accuracy:', score[1])\n",
        "  print('+++++++++++++++++++++++++++++++++++')\n",
        "  test_accuracy_results[n_examples_per_class] = score[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.9870 - accuracy: 0.2000\n",
            "Epoch 00001: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_1_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_1_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.9870 - accuracy: 0.2000 - val_loss: 1.6409 - val_accuracy: 0.2503\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.3614 - accuracy: 0.2000\n",
            "Epoch 00002: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_1_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_1_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.3614 - accuracy: 0.2000 - val_loss: 1.5648 - val_accuracy: 0.3229\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9777 - accuracy: 0.8000\n",
            "Epoch 00003: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_1_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_1_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.9777 - accuracy: 0.8000 - val_loss: 1.4961 - val_accuracy: 0.3887\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6891 - accuracy: 1.0000\n",
            "Epoch 00004: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_1_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_1_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6891 - accuracy: 1.0000 - val_loss: 1.4400 - val_accuracy: 0.4329\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4122 - accuracy: 1.0000\n",
            "Epoch 00005: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_1_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_1_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.4122 - accuracy: 1.0000 - val_loss: 1.3945 - val_accuracy: 0.4582\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4110 - accuracy: 1.0000\n",
            "Epoch 00006: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_1_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_1_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4110 - accuracy: 1.0000 - val_loss: 1.3543 - val_accuracy: 0.4794\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4644 - accuracy: 1.0000\n",
            "Epoch 00007: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_1_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_1_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.4644 - accuracy: 1.0000 - val_loss: 1.3223 - val_accuracy: 0.4955\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2630 - accuracy: 1.0000\n",
            "Epoch 00008: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_1_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_1_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2630 - accuracy: 1.0000 - val_loss: 1.2988 - val_accuracy: 0.5067\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1769 - accuracy: 1.0000\n",
            "Epoch 00009: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_1_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_1_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1769 - accuracy: 1.0000 - val_loss: 1.2802 - val_accuracy: 0.5158\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1641 - accuracy: 1.0000\n",
            "Epoch 00010: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_1_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_1_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.1641 - accuracy: 1.0000 - val_loss: 1.2655 - val_accuracy: 0.5241\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 1.2680 - accuracy: 0.5069\n",
            "+++++++++++++++++++++++++++++++++++\n",
            "num examples per class 1\n",
            "Test score: 1.2679877281188965\n",
            "Test accuracy: 0.5068916082382202\n",
            "+++++++++++++++++++++++++++++++++++\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.6592 - accuracy: 0.2400\n",
            "Epoch 00001: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_5_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_5_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.6592 - accuracy: 0.2400 - val_loss: 1.4929 - val_accuracy: 0.3719\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.4695 - accuracy: 0.3200\n",
            "Epoch 00002: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_5_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_5_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.4695 - accuracy: 0.3200 - val_loss: 1.3490 - val_accuracy: 0.4735\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.1376 - accuracy: 0.5200\n",
            "Epoch 00003: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_5_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_5_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.1376 - accuracy: 0.5200 - val_loss: 1.2409 - val_accuracy: 0.5550\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8041 - accuracy: 0.8000\n",
            "Epoch 00004: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_5_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_5_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.8041 - accuracy: 0.8000 - val_loss: 1.1559 - val_accuracy: 0.6183\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7061 - accuracy: 0.9200\n",
            "Epoch 00005: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_5_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_5_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.7061 - accuracy: 0.9200 - val_loss: 1.0881 - val_accuracy: 0.6545\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5999 - accuracy: 0.8800\n",
            "Epoch 00006: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_5_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_5_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5999 - accuracy: 0.8800 - val_loss: 1.0339 - val_accuracy: 0.6756\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5433 - accuracy: 0.8800\n",
            "Epoch 00007: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_5_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_5_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.5433 - accuracy: 0.8800 - val_loss: 0.9907 - val_accuracy: 0.6906\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4205 - accuracy: 0.9600\n",
            "Epoch 00008: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_5_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_5_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4205 - accuracy: 0.9600 - val_loss: 0.9568 - val_accuracy: 0.7011\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.3585 - accuracy: 0.9600\n",
            "Epoch 00009: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_5_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_5_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3585 - accuracy: 0.9600 - val_loss: 0.9298 - val_accuracy: 0.7064\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.2701 - accuracy: 1.0000\n",
            "Epoch 00010: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_5_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_5_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2701 - accuracy: 1.0000 - val_loss: 0.9096 - val_accuracy: 0.7116\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.8671 - accuracy: 0.7227\n",
            "+++++++++++++++++++++++++++++++++++\n",
            "num examples per class 5\n",
            "Test score: 0.8670715093612671\n",
            "Test accuracy: 0.7226908206939697\n",
            "+++++++++++++++++++++++++++++++++++\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.0562 - accuracy: 0.2400\n",
            "Epoch 00001: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_10_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_10_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 2s 2s/step - loss: 2.0562 - accuracy: 0.2400 - val_loss: 1.6351 - val_accuracy: 0.3011\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.6986 - accuracy: 0.3200\n",
            "Epoch 00002: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_10_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_10_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.6986 - accuracy: 0.3200 - val_loss: 1.3930 - val_accuracy: 0.4593\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.3281 - accuracy: 0.5000\n",
            "Epoch 00003: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_10_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_10_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.3281 - accuracy: 0.5000 - val_loss: 1.2190 - val_accuracy: 0.5941\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 1.1156 - accuracy: 0.6000\n",
            "Epoch 00004: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_10_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_10_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.1156 - accuracy: 0.6000 - val_loss: 1.0968 - val_accuracy: 0.6412\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.9229 - accuracy: 0.7600\n",
            "Epoch 00005: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_10_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_10_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.9229 - accuracy: 0.7600 - val_loss: 1.0086 - val_accuracy: 0.6752\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7767 - accuracy: 0.8600\n",
            "Epoch 00006: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_10_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_10_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.7767 - accuracy: 0.8600 - val_loss: 0.9414 - val_accuracy: 0.7031\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6683 - accuracy: 0.8400\n",
            "Epoch 00007: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_10_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_10_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6683 - accuracy: 0.8400 - val_loss: 0.8875 - val_accuracy: 0.7264\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.5763 - accuracy: 0.8800\n",
            "Epoch 00008: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_10_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_10_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5763 - accuracy: 0.8800 - val_loss: 0.8439 - val_accuracy: 0.7429\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4901 - accuracy: 0.9600\n",
            "Epoch 00009: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_10_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_10_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.4901 - accuracy: 0.9600 - val_loss: 0.8075 - val_accuracy: 0.7555\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.4475 - accuracy: 0.9200\n",
            "Epoch 00010: saving model to /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_10_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_fc_tl_10_samples_per_class/cp.ckpt/assets\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4475 - accuracy: 0.9200 - val_loss: 0.7772 - val_accuracy: 0.7654\n",
            "152/152 [==============================] - 0s 3ms/step - loss: 0.7268 - accuracy: 0.7776\n",
            "+++++++++++++++++++++++++++++++++++\n",
            "num examples per class 10\n",
            "Test score: 0.7268171906471252\n",
            "Test accuracy: 0.7776177525520325\n",
            "+++++++++++++++++++++++++++++++++++\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYiu6jrXJJ04",
        "colab_type": "code",
        "outputId": "41f78ca2-d49f-46af-8b98-f43f7c485317",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print_accuracy_results(test_accuracy_results)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num examples per class: accuracy\n",
            "1: 0.5069\n",
            "5: 0.7227\n",
            "10: 0.7776\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lbx43UEfrHo4",
        "colab_type": "text"
      },
      "source": [
        "## CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcSZOpkorcqq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_data_cnn_model(X, y, label_map=None):\n",
        "  X = X.reshape(X.shape[0], X.shape[1], X.shape[2], 1) # reshape 60,000 28 x 28 matrices into 60,000 784-length vectors.\n",
        "  X = X.astype('float32')\n",
        "  X /= 255\n",
        "\n",
        "  if label_map is None:\n",
        "    label_map = {}\n",
        "    class_labels = np.unique(y)\n",
        "    for i in range(len(class_labels)):\n",
        "      label_map[class_labels[i]] = i\n",
        "\n",
        "  def map_label(label):\n",
        "    return label_map[label]\n",
        "\n",
        "  nb_classes = len(np.unique(y))\n",
        "  y = np.vectorize(map_label)(y)\n",
        "  y = np_utils.to_categorical(y, nb_classes)\n",
        "\n",
        "  return X, y, label_map"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhGGq1trr3PC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_simple_cnn(\n",
        "    input_shape,\n",
        "    num_classes,\n",
        "    filters,\n",
        "    fc_sizes,\n",
        "    dropout_prob):\n",
        "  model = Sequential()                                 # Linear stacking of layers\n",
        "\n",
        "  # Convolution Layer 1\n",
        "  filter0 = filters[0]\n",
        "  model.add(Conv2D(filter0[0], (filter0[1], filter0[2]), input_shape=input_shape)) # 32 different 3x3 kernels -- so 32 feature maps\n",
        "  model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n",
        "  convLayer01 = Activation('relu')                     # activation\n",
        "  model.add(convLayer01)\n",
        "\n",
        "  # Convolution Layer 2\n",
        "  filter1 = filters[1]\n",
        "  model.add(Conv2D(filter1[0], (filter1[1], filter1[2])))                        # 32 different 3x3 kernels -- so 32 feature maps\n",
        "  model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n",
        "  model.add(Activation('relu'))                        # activation\n",
        "  convLayer02 = MaxPooling2D(pool_size=(2,2))          # Pool the max values over a 2x2 kernel\n",
        "  model.add(convLayer02)\n",
        "\n",
        "  # Convolution Layer 3\n",
        "  filter2 = filters[2]\n",
        "  model.add(Conv2D(filter2[0],(filter2[1], filter2[2])))                         # 64 different 3x3 kernels -- so 64 feature maps\n",
        "  model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n",
        "  convLayer03 = Activation('relu')                     # activation\n",
        "  model.add(convLayer03)\n",
        "\n",
        "  # Convolution Layer 4\n",
        "  filter3 = filters[3]\n",
        "  model.add(Conv2D(filter3[0], (filter3[1], filter3[2])))                        # 64 different 3x3 kernels -- so 64 feature maps\n",
        "  model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n",
        "  model.add(Activation('relu'))                        # activation\n",
        "  convLayer04 = MaxPooling2D(pool_size=(2,2))          # Pool the max values over a 2x2 kernel\n",
        "  model.add(convLayer04)\n",
        "  model.add(Flatten())                                 # Flatten final 4x4x64 output matrix into a 1024-length vector\n",
        "\n",
        "  # Fully Connected Layer 5\n",
        "  model.add(Dense(fc_sizes[0]))                                # 512 FCN nodes\n",
        "  model.add(BatchNormalization())                      # normalization\n",
        "  model.add(Activation('relu'))                        # activation\n",
        "                       \n",
        "  model.add(Dropout(dropout_prob))                              # 20% dropout of randomly selected nodes\n",
        "  \n",
        "  # Fully Connected Layer 6\n",
        "  model.add(Dense(num_classes))                                 # final 10 FCN nodes\n",
        "  model.add(Activation('softmax'))                     # softmax activation\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7kDAQ6CMJX1",
        "colab_type": "text"
      },
      "source": [
        "### Sanity Check (Train and Eval on the Entire Target Training Set)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RryvovmWsYjR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = create_simple_cnn(\n",
        "    input_shape=(28,28,1),\n",
        "    num_classes=5,\n",
        "    filters=[(32,3,3),(32,3,3),(64,3,3),(64,3,3)],\n",
        "    fc_sizes=[512],\n",
        "    dropout_prob=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVjNmuZ_L3s1",
        "colab_type": "code",
        "outputId": "5c47d270-0b1f-4a56-92ea-d19844659c58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_31 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "batch_normalization_39 (Batc (None, 26, 26, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_56 (Activation)   (None, 26, 26, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_32 (Conv2D)           (None, 24, 24, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_40 (Batc (None, 24, 24, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_57 (Activation)   (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_33 (Conv2D)           (None, 10, 10, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_41 (Batc (None, 10, 10, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_58 (Activation)   (None, 10, 10, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_34 (Conv2D)           (None, 8, 8, 64)          36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_42 (Batc (None, 8, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "activation_59 (Activation)   (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling (None, 4, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "batch_normalization_43 (Batc (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "activation_60 (Activation)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 5)                 2565      \n",
            "_________________________________________________________________\n",
            "activation_61 (Activation)   (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 595,173\n",
            "Trainable params: 593,765\n",
            "Non-trainable params: 1,408\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZG3vZbNzMZzQ",
        "colab": {}
      },
      "source": [
        "X_train_tgt_sample, y_train_tgt_sample = subsample_train_data(X_train_tgt[:-1000], y_train_tgt[:-1000], 10000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Die-09FDMZzZ",
        "colab": {}
      },
      "source": [
        "X_train_tgt_cnn_sample, y_train_tgt_cnn_sample, label_map = preprocess_data_cnn_model(X_train_tgt_sample, y_train_tgt_sample)\n",
        "X_valid_tgt_cnn, y_valid_tgt_cnn, label_map = preprocess_data_cnn_model(X_train_tgt[1000:], y_train_tgt[1000:], label_map)\n",
        "X_test_tgt_cnn, y_test_tgt_cnn, label_map = preprocess_data_cnn_model(X_test_tgt, y_test_tgt, label_map)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Pck7gMWsDHm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n",
        "                         height_shift_range=0.08, zoom_range=0.08)\n",
        "\n",
        "test_gen = ImageDataGenerator()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5z7hPuosMr8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_generator = gen.flow(X_train_tgt_cnn_sample, y_train_tgt_cnn_sample, batch_size=128)\n",
        "test_generator = test_gen.flow(X_valid_tgt_cnn, y_valid_tgt_cnn, batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CUSfCWZNZG-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_path = output_dir+\"mnist_cnn_sanity_check/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create a callback that saves the model's weights\n",
        "cp_callback = ModelCheckpoint(filepath=checkpoint_path,\n",
        "                              verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHQ6HyszsOfZ",
        "colab_type": "code",
        "outputId": "36dcf8d9-7040-4511-896b-9146f3dcfdba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "model.fit(train_generator, \n",
        "          steps_per_epoch=60000//128, \n",
        "          epochs=5, \n",
        "          verbose=1, \n",
        "          validation_data=test_generator,\n",
        "          validation_steps=10000//128,\n",
        "          callbacks=[cp_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "468/468 [==============================] - ETA: 0s - loss: 0.0132 - accuracy: 0.9955\n",
            "Epoch 00001: saving model to /content/gdrive/My Drive/cs231n_project/mnist_cnn_sanity_check/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_cnn_sanity_check/cp.ckpt/assets\n",
            "468/468 [==============================] - 25s 53ms/step - loss: 0.0132 - accuracy: 0.9955 - val_loss: 0.0041 - val_accuracy: 0.9988\n",
            "Epoch 2/5\n",
            "468/468 [==============================] - ETA: 0s - loss: 0.0122 - accuracy: 0.9958\n",
            "Epoch 00002: saving model to /content/gdrive/My Drive/cs231n_project/mnist_cnn_sanity_check/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_cnn_sanity_check/cp.ckpt/assets\n",
            "468/468 [==============================] - 25s 53ms/step - loss: 0.0122 - accuracy: 0.9958 - val_loss: 0.0072 - val_accuracy: 0.9973\n",
            "Epoch 3/5\n",
            "468/468 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 0.9965\n",
            "Epoch 00003: saving model to /content/gdrive/My Drive/cs231n_project/mnist_cnn_sanity_check/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_cnn_sanity_check/cp.ckpt/assets\n",
            "468/468 [==============================] - 25s 53ms/step - loss: 0.0106 - accuracy: 0.9965 - val_loss: 0.0057 - val_accuracy: 0.9981\n",
            "Epoch 4/5\n",
            "467/468 [============================>.] - ETA: 0s - loss: 0.0102 - accuracy: 0.9968\n",
            "Epoch 00004: saving model to /content/gdrive/My Drive/cs231n_project/mnist_cnn_sanity_check/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_cnn_sanity_check/cp.ckpt/assets\n",
            "468/468 [==============================] - 26s 55ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.0133 - val_accuracy: 0.9953\n",
            "Epoch 5/5\n",
            "468/468 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.9969\n",
            "Epoch 00005: saving model to /content/gdrive/My Drive/cs231n_project/mnist_cnn_sanity_check/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_cnn_sanity_check/cp.ckpt/assets\n",
            "468/468 [==============================] - 25s 53ms/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.0039 - val_accuracy: 0.9989\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f59c721e4e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8t7WeXKNuiU",
        "colab_type": "code",
        "outputId": "82caaf7b-5e98-4911-8fbc-1626688fd2f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "score = model.evaluate(X_test_tgt_cnn, y_test_tgt_cnn)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "152/152 [==============================] - 1s 3ms/step - loss: 0.0093 - accuracy: 0.9973\n",
            "Test score: 0.009285828098654747\n",
            "Test accuracy: 0.9973256587982178\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRRusYA33fOF",
        "colab_type": "text"
      },
      "source": [
        "### Baseline No Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1Lzrky2Oev4",
        "colab_type": "code",
        "outputId": "aa2080e4-2afb-4edf-f989-912cb8fb2bb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "test_accuracy_results = {}\n",
        "\n",
        "for n_examples_per_class in n_examples_per_class_list:\n",
        "  X_train_tgt_sample, y_train_tgt_sample = subsample_train_data(X_train_tgt[:-1000], y_train_tgt[:-1000], n_examples_per_class)\n",
        "  assert len(y_train_tgt_sample) <= n_examples_per_class * len(np.unique(y_train_tgt))\n",
        "  \n",
        "  X_train_tgt_cnn_sample, y_train_tgt_cnn_sample, label_map = preprocess_data_cnn_model(X_train_tgt_sample, y_train_tgt_sample)\n",
        "  X_valid_tgt_cnn, y_valid_tgt_cnn, label_map = preprocess_data_cnn_model(X_train_tgt[1000:], y_train_tgt[1000:], label_map)\n",
        "  X_test_tgt_cnn, y_test_tgt_cnn, label_map = preprocess_data_cnn_model(X_test_tgt, y_test_tgt, label_map)\n",
        "\n",
        "  model = create_simple_cnn(\n",
        "      input_shape=(28,28,1),\n",
        "      num_classes=5,\n",
        "      filters=[(32,3,3),(32,3,3),(64,3,3),(64,3,3)],\n",
        "      fc_sizes=[512],\n",
        "      dropout_prob=0.2)\n",
        "  \n",
        "  gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n",
        "                         height_shift_range=0.08, zoom_range=0.08)\n",
        "  test_gen = ImageDataGenerator()\n",
        "\n",
        "  train_generator = gen.flow(X_train_tgt_cnn_sample, y_train_tgt_cnn_sample, batch_size=128)\n",
        "  test_generator = test_gen.flow(X_valid_tgt_cnn, y_valid_tgt_cnn, batch_size=128)\n",
        "\n",
        "  # checkpoint_path = \"cs231n/project/model_checkpoints/minist_fc_test/cp.ckpt\"\n",
        "  checkpoint_path = output_dir+\"mnist_cnn_no_tl_{}_samples_per_class/cp.ckpt\".format(n_examples_per_class)\n",
        "  checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "  # Create a callback that saves the model's weights\n",
        "  cp_callback = ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                verbose=1)\n",
        "  model.fit(train_generator, \n",
        "            steps_per_epoch=60000//128, \n",
        "            epochs=5, \n",
        "            verbose=1, \n",
        "            validation_data=test_generator,\n",
        "            validation_steps=10000//128,\n",
        "            callbacks=[cp_callback])\n",
        "  \n",
        "  score = model.evaluate(X_test_tgt_cnn, y_test_tgt_cnn)\n",
        "  print('+++++++++++++++++++++++++++++++++++')\n",
        "  print('num examples per class', n_examples_per_class)\n",
        "  print('Test score:', score[0])\n",
        "  print('Test accuracy:', score[1])\n",
        "  print('+++++++++++++++++++++++++++++++++++')\n",
        "  test_accuracy_results[n_examples_per_class] = score[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "464/468 [============================>.] - ETA: 0s - loss: 0.0135 - accuracy: 0.9953\n",
            "Epoch 00001: saving model to /content/gdrive/My Drive/cs231n_project/mnist_cnn_no_tl_1_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_cnn_no_tl_1_samples_per_class/cp.ckpt/assets\n",
            "468/468 [==============================] - 8s 16ms/step - loss: 0.0133 - accuracy: 0.9953 - val_loss: 2.5064 - val_accuracy: 0.4796\n",
            "Epoch 2/5\n",
            "464/468 [============================>.] - ETA: 0s - loss: 7.2892e-05 - accuracy: 1.0000\n",
            "Epoch 00002: saving model to /content/gdrive/My Drive/cs231n_project/mnist_cnn_no_tl_1_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_cnn_no_tl_1_samples_per_class/cp.ckpt/assets\n",
            "468/468 [==============================] - 7s 16ms/step - loss: 7.2586e-05 - accuracy: 1.0000 - val_loss: 1.3172 - val_accuracy: 0.6946\n",
            "Epoch 3/5\n",
            "466/468 [============================>.] - ETA: 0s - loss: 2.7670e-05 - accuracy: 1.0000\n",
            "Epoch 00003: saving model to /content/gdrive/My Drive/cs231n_project/mnist_cnn_no_tl_1_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_cnn_no_tl_1_samples_per_class/cp.ckpt/assets\n",
            "468/468 [==============================] - 8s 17ms/step - loss: 2.7595e-05 - accuracy: 1.0000 - val_loss: 1.3747 - val_accuracy: 0.6955\n",
            "Epoch 4/5\n",
            "468/468 [==============================] - ETA: 0s - loss: 1.5379e-05 - accuracy: 1.0000\n",
            "Epoch 00004: saving model to /content/gdrive/My Drive/cs231n_project/mnist_cnn_no_tl_1_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_cnn_no_tl_1_samples_per_class/cp.ckpt/assets\n",
            "468/468 [==============================] - 7s 16ms/step - loss: 1.5379e-05 - accuracy: 1.0000 - val_loss: 1.4082 - val_accuracy: 0.6891\n",
            "Epoch 5/5\n",
            "465/468 [============================>.] - ETA: 0s - loss: 1.1032e-05 - accuracy: 1.0000\n",
            "Epoch 00005: saving model to /content/gdrive/My Drive/cs231n_project/mnist_cnn_no_tl_1_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_cnn_no_tl_1_samples_per_class/cp.ckpt/assets\n",
            "468/468 [==============================] - 7s 16ms/step - loss: 1.1018e-05 - accuracy: 1.0000 - val_loss: 1.4285 - val_accuracy: 0.6921\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 1.3117 - accuracy: 0.7046\n",
            "+++++++++++++++++++++++++++++++++++\n",
            "num examples per class 1\n",
            "Test score: 1.3117215633392334\n",
            "Test accuracy: 0.7045875191688538\n",
            "+++++++++++++++++++++++++++++++++++\n",
            "Epoch 1/5\n",
            "465/468 [============================>.] - ETA: 0s - loss: 0.0118 - accuracy: 0.9958\n",
            "Epoch 00001: saving model to /content/gdrive/My Drive/cs231n_project/mnist_cnn_no_tl_5_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_cnn_no_tl_5_samples_per_class/cp.ckpt/assets\n",
            "468/468 [==============================] - 11s 23ms/step - loss: 0.0117 - accuracy: 0.9958 - val_loss: 0.9440 - val_accuracy: 0.7315\n",
            "Epoch 2/5\n",
            "467/468 [============================>.] - ETA: 0s - loss: 8.8302e-05 - accuracy: 1.0000\n",
            "Epoch 00002: saving model to /content/gdrive/My Drive/cs231n_project/mnist_cnn_no_tl_5_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_cnn_no_tl_5_samples_per_class/cp.ckpt/assets\n",
            "468/468 [==============================] - 12s 25ms/step - loss: 8.8184e-05 - accuracy: 1.0000 - val_loss: 0.7950 - val_accuracy: 0.8012\n",
            "Epoch 3/5\n",
            "468/468 [==============================] - ETA: 0s - loss: 4.3360e-05 - accuracy: 1.0000\n",
            "Epoch 00003: saving model to /content/gdrive/My Drive/cs231n_project/mnist_cnn_no_tl_5_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_cnn_no_tl_5_samples_per_class/cp.ckpt/assets\n",
            "468/468 [==============================] - 11s 23ms/step - loss: 4.3360e-05 - accuracy: 1.0000 - val_loss: 0.8094 - val_accuracy: 0.8045\n",
            "Epoch 4/5\n",
            "466/468 [============================>.] - ETA: 0s - loss: 2.7136e-05 - accuracy: 1.0000\n",
            "Epoch 00004: saving model to /content/gdrive/My Drive/cs231n_project/mnist_cnn_no_tl_5_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_cnn_no_tl_5_samples_per_class/cp.ckpt/assets\n",
            "468/468 [==============================] - 11s 22ms/step - loss: 2.7125e-05 - accuracy: 1.0000 - val_loss: 0.8566 - val_accuracy: 0.8005\n",
            "Epoch 5/5\n",
            "465/468 [============================>.] - ETA: 0s - loss: 1.4808e-05 - accuracy: 1.0000\n",
            "Epoch 00005: saving model to /content/gdrive/My Drive/cs231n_project/mnist_cnn_no_tl_5_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_cnn_no_tl_5_samples_per_class/cp.ckpt/assets\n",
            "468/468 [==============================] - 11s 22ms/step - loss: 1.4741e-05 - accuracy: 1.0000 - val_loss: 0.7743 - val_accuracy: 0.8201\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.7980 - accuracy: 0.8216\n",
            "+++++++++++++++++++++++++++++++++++\n",
            "num examples per class 5\n",
            "Test score: 0.7979503273963928\n",
            "Test accuracy: 0.8216416239738464\n",
            "+++++++++++++++++++++++++++++++++++\n",
            "Epoch 1/5\n",
            "467/468 [============================>.] - ETA: 0s - loss: 0.0120 - accuracy: 0.9966\n",
            "Epoch 00001: saving model to /content/gdrive/My Drive/cs231n_project/mnist_cnn_no_tl_10_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_cnn_no_tl_10_samples_per_class/cp.ckpt/assets\n",
            "468/468 [==============================] - 15s 32ms/step - loss: 0.0120 - accuracy: 0.9966 - val_loss: 0.5385 - val_accuracy: 0.8513\n",
            "Epoch 2/5\n",
            "467/468 [============================>.] - ETA: 0s - loss: 1.0091e-04 - accuracy: 1.0000\n",
            "Epoch 00002: saving model to /content/gdrive/My Drive/cs231n_project/mnist_cnn_no_tl_10_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_cnn_no_tl_10_samples_per_class/cp.ckpt/assets\n",
            "468/468 [==============================] - 14s 30ms/step - loss: 1.0078e-04 - accuracy: 1.0000 - val_loss: 0.2737 - val_accuracy: 0.9233\n",
            "Epoch 3/5\n",
            "468/468 [==============================] - ETA: 0s - loss: 4.4314e-05 - accuracy: 1.0000\n",
            "Epoch 00003: saving model to /content/gdrive/My Drive/cs231n_project/mnist_cnn_no_tl_10_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_cnn_no_tl_10_samples_per_class/cp.ckpt/assets\n",
            "468/468 [==============================] - 14s 30ms/step - loss: 4.4314e-05 - accuracy: 1.0000 - val_loss: 0.2874 - val_accuracy: 0.9253\n",
            "Epoch 4/5\n",
            "466/468 [============================>.] - ETA: 0s - loss: 2.1296e-05 - accuracy: 1.0000\n",
            "Epoch 00004: saving model to /content/gdrive/My Drive/cs231n_project/mnist_cnn_no_tl_10_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_cnn_no_tl_10_samples_per_class/cp.ckpt/assets\n",
            "468/468 [==============================] - 14s 30ms/step - loss: 2.1268e-05 - accuracy: 1.0000 - val_loss: 0.2986 - val_accuracy: 0.9228\n",
            "Epoch 5/5\n",
            "466/468 [============================>.] - ETA: 0s - loss: 1.3966e-05 - accuracy: 1.0000\n",
            "Epoch 00005: saving model to /content/gdrive/My Drive/cs231n_project/mnist_cnn_no_tl_10_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_cnn_no_tl_10_samples_per_class/cp.ckpt/assets\n",
            "468/468 [==============================] - 14s 30ms/step - loss: 1.3941e-05 - accuracy: 1.0000 - val_loss: 0.2777 - val_accuracy: 0.9290\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.2427 - accuracy: 0.9313\n",
            "+++++++++++++++++++++++++++++++++++\n",
            "num examples per class 10\n",
            "Test score: 0.24274489283561707\n",
            "Test accuracy: 0.9312898516654968\n",
            "+++++++++++++++++++++++++++++++++++\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPnS5aeiQODN",
        "colab_type": "code",
        "outputId": "5efd4b3a-8e11-4bf3-9f51-a2755d5c5f5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print_accuracy_results(test_accuracy_results)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num examples per class: accuracy\n",
            "1: 0.7046\n",
            "5: 0.8216\n",
            "10: 0.9313\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHm-WOdl3pCz",
        "colab_type": "text"
      },
      "source": [
        "### With Tranfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSt88mnhQFAi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_src_cnn, y_train_src_cnn, label_map = preprocess_data_cnn_model(X_train_src, y_train_src)\n",
        "X_test_src_cnn, y_test_src_cnn, label_map = preprocess_data_cnn_model(X_test_src, y_test_src, label_map)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LlO0f681uXM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pre_trained_model = create_simple_cnn(\n",
        "    input_shape=(28,28,1),\n",
        "    num_classes=5,\n",
        "    filters=[(32,3,3),(32,3,3),(64,3,3),(64,3,3)],\n",
        "    fc_sizes=[512],\n",
        "    dropout_prob=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAxnctc2P36V",
        "colab_type": "code",
        "outputId": "6a673374-b0cd-4cd9-af8b-142be9c911f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "pre_trained_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_67 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "batch_normalization_88 (Batc (None, 26, 26, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_118 (Activation)  (None, 26, 26, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_68 (Conv2D)           (None, 24, 24, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_89 (Batc (None, 24, 24, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_119 (Activation)  (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_33 (MaxPooling (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_69 (Conv2D)           (None, 10, 10, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_90 (Batc (None, 10, 10, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_120 (Activation)  (None, 10, 10, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_70 (Conv2D)           (None, 8, 8, 64)          36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_91 (Batc (None, 8, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "activation_121 (Activation)  (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_34 (MaxPooling (None, 4, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_16 (Flatten)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_46 (Dense)             (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "batch_normalization_92 (Batc (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "activation_122 (Activation)  (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_30 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_47 (Dense)             (None, 5)                 2565      \n",
            "_________________________________________________________________\n",
            "activation_123 (Activation)  (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 595,173\n",
            "Trainable params: 593,765\n",
            "Non-trainable params: 1,408\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0lPoz2_Qjnk",
        "colab_type": "code",
        "outputId": "7521a003-ec0e-4d79-a565-a6e447935f3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print_class_distribution(y_test_src)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0: 980\n",
            "1: 1135\n",
            "2: 1032\n",
            "3: 1010\n",
            "4: 982\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h5bqqieiQ5n7",
        "colab": {}
      },
      "source": [
        "checkpoint_path = output_dir+\"mnist_cnn_tl_pretrained_model/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create a callback that saves the model's weights\n",
        "cp_callback = ModelCheckpoint(filepath=checkpoint_path,\n",
        "                              verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "579bfd0a-6838-4484-fa7d-b551b007022e",
        "id": "ZD26ZeuCQ5oC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        }
      },
      "source": [
        "pre_trained_model.fit(X_train_src_cnn[:-1000], y_train_src_cnn[:-1000],\n",
        "          batch_size=128, \n",
        "          epochs=10,\n",
        "          verbose=1,\n",
        "          validation_data=(X_train_src_cnn[1000:], y_train_src_cnn[1000:]),\n",
        "          callbacks=[cp_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "229/232 [============================>.] - ETA: 0s - loss: 0.0451 - accuracy: 0.9852\n",
            "Epoch 00001: saving model to /content/gdrive/My Drive/cs231n_project/mnist_cnn_tl_pretrained_model/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_cnn_tl_pretrained_model/cp.ckpt/assets\n",
            "232/232 [==============================] - 6s 27ms/step - loss: 0.0448 - accuracy: 0.9852 - val_loss: 6.5900 - val_accuracy: 0.2204\n",
            "Epoch 2/10\n",
            "232/232 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 0.9971\n",
            "Epoch 00002: saving model to /content/gdrive/My Drive/cs231n_project/mnist_cnn_tl_pretrained_model/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_cnn_tl_pretrained_model/cp.ckpt/assets\n",
            "232/232 [==============================] - 6s 26ms/step - loss: 0.0102 - accuracy: 0.9971 - val_loss: 0.2529 - val_accuracy: 0.9022\n",
            "Epoch 3/10\n",
            "226/232 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.9983\n",
            "Epoch 00003: saving model to /content/gdrive/My Drive/cs231n_project/mnist_cnn_tl_pretrained_model/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_cnn_tl_pretrained_model/cp.ckpt/assets\n",
            "232/232 [==============================] - 7s 29ms/step - loss: 0.0056 - accuracy: 0.9983 - val_loss: 0.0029 - val_accuracy: 0.9994\n",
            "Epoch 4/10\n",
            "228/232 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9990\n",
            "Epoch 00004: saving model to /content/gdrive/My Drive/cs231n_project/mnist_cnn_tl_pretrained_model/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_cnn_tl_pretrained_model/cp.ckpt/assets\n",
            "232/232 [==============================] - 6s 26ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.0064 - val_accuracy: 0.9978\n",
            "Epoch 5/10\n",
            "229/232 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9983\n",
            "Epoch 00005: saving model to /content/gdrive/My Drive/cs231n_project/mnist_cnn_tl_pretrained_model/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_cnn_tl_pretrained_model/cp.ckpt/assets\n",
            "232/232 [==============================] - 6s 26ms/step - loss: 0.0050 - accuracy: 0.9983 - val_loss: 0.0101 - val_accuracy: 0.9970\n",
            "Epoch 6/10\n",
            "229/232 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9990\n",
            "Epoch 00006: saving model to /content/gdrive/My Drive/cs231n_project/mnist_cnn_tl_pretrained_model/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_cnn_tl_pretrained_model/cp.ckpt/assets\n",
            "232/232 [==============================] - 6s 26ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0028 - val_accuracy: 0.9993\n",
            "Epoch 7/10\n",
            "232/232 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9990\n",
            "Epoch 00007: saving model to /content/gdrive/My Drive/cs231n_project/mnist_cnn_tl_pretrained_model/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_cnn_tl_pretrained_model/cp.ckpt/assets\n",
            "232/232 [==============================] - 7s 30ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.0029 - val_accuracy: 0.9992\n",
            "Epoch 8/10\n",
            "229/232 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9991\n",
            "Epoch 00008: saving model to /content/gdrive/My Drive/cs231n_project/mnist_cnn_tl_pretrained_model/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_cnn_tl_pretrained_model/cp.ckpt/assets\n",
            "232/232 [==============================] - 6s 26ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0034 - val_accuracy: 0.9992\n",
            "Epoch 9/10\n",
            "227/232 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9994\n",
            "Epoch 00009: saving model to /content/gdrive/My Drive/cs231n_project/mnist_cnn_tl_pretrained_model/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_cnn_tl_pretrained_model/cp.ckpt/assets\n",
            "232/232 [==============================] - 6s 26ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0029 - val_accuracy: 0.9993\n",
            "Epoch 10/10\n",
            "232/232 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9995\n",
            "Epoch 00010: saving model to /content/gdrive/My Drive/cs231n_project/mnist_cnn_tl_pretrained_model/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_cnn_tl_pretrained_model/cp.ckpt/assets\n",
            "232/232 [==============================] - 7s 29ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0053 - val_accuracy: 0.9984\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f59a4d40e48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jrh53owOT-RL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pre_trained_model = tf.keras.models.load_model(output_dir+\"mnist_cnn_tl_pretrained_model/cp.ckpt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vi-VuYHe6T2W",
        "colab_type": "code",
        "outputId": "db279b38-dab8-4b95-a4f1-aa452e424d84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "score = pre_trained_model.evaluate(X_test_src_cnn, y_test_src_cnn)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "161/161 [==============================] - 1s 3ms/step - loss: 0.0146 - accuracy: 0.9965\n",
            "Test score: 0.014575857669115067\n",
            "Test accuracy: 0.996497392654419\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crApdxhBVDiV",
        "colab_type": "code",
        "outputId": "ba85010b-f45c-4c61-e5c0-97d84d7629e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "score = pre_trained_model.evaluate(X_test_tgt_cnn, y_test_tgt_cnn)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "152/152 [==============================] - 1s 3ms/step - loss: 6.5088 - accuracy: 0.3205\n",
            "Test score: 6.508804798126221\n",
            "Test accuracy: 0.3205101788043976\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdO324aR6jJt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable=False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qYhlkQj6YOi",
        "colab_type": "code",
        "outputId": "9c6996de-4ebf-41b1-ad64-f821e2bc23b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "pre_trained_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_67 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "batch_normalization_88 (Batc (None, 26, 26, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_118 (Activation)  (None, 26, 26, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_68 (Conv2D)           (None, 24, 24, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_89 (Batc (None, 24, 24, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_119 (Activation)  (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_33 (MaxPooling (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_69 (Conv2D)           (None, 10, 10, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_90 (Batc (None, 10, 10, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_120 (Activation)  (None, 10, 10, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_70 (Conv2D)           (None, 8, 8, 64)          36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_91 (Batc (None, 8, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "activation_121 (Activation)  (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_34 (MaxPooling (None, 4, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_16 (Flatten)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_46 (Dense)             (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "batch_normalization_92 (Batc (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "activation_122 (Activation)  (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_30 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_47 (Dense)             (None, 5)                 2565      \n",
            "_________________________________________________________________\n",
            "activation_123 (Activation)  (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 595,173\n",
            "Trainable params: 0\n",
            "Non-trainable params: 595,173\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LWstZtfRXQ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_fine_tune_cnn_model(\n",
        "    pre_trained_model,\n",
        "    num_classes,\n",
        "    fc_sizes,\n",
        "    dropout_prob):\n",
        "  output = pre_trained_model.layers[-7].output\n",
        "  output = Dense(fc_sizes[0])(output)\n",
        "  output = BatchNormalization()(output)\n",
        "  output = Activation('relu')(output)\n",
        "  output = Dropout(dropout_prob)(output)\n",
        "  output = Dense(num_classes)(output)\n",
        "  output = Activation('softmax')(output)\n",
        "  fine_tune_model = Model(inputs=pre_trained_model.inputs, outputs=output)\n",
        "  fine_tune_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  return fine_tune_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_HcQ-Ay6tjc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fine_tune_model = create_fine_tune_cnn_model(\n",
        "    pre_trained_model,\n",
        "    num_classes=5,\n",
        "    fc_sizes=[512],\n",
        "    dropout_prob=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8CA844o73Wd",
        "colab_type": "code",
        "outputId": "a1dd9fb6-bee6-4dc7-e348-ed4db2afb303",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        }
      },
      "source": [
        "fine_tune_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_9 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d_67 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "batch_normalization_88 (Batc (None, 26, 26, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_118 (Activation)  (None, 26, 26, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_68 (Conv2D)           (None, 24, 24, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_89 (Batc (None, 24, 24, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_119 (Activation)  (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_33 (MaxPooling (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_69 (Conv2D)           (None, 10, 10, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_90 (Batc (None, 10, 10, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_120 (Activation)  (None, 10, 10, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_70 (Conv2D)           (None, 8, 8, 64)          36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_91 (Batc (None, 8, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "activation_121 (Activation)  (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_34 (MaxPooling (None, 4, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_16 (Flatten)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_48 (Dense)             (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "batch_normalization_93 (Batc (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "activation_124 (Activation)  (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_31 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_49 (Dense)             (None, 5)                 2565      \n",
            "_________________________________________________________________\n",
            "activation_125 (Activation)  (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 595,173\n",
            "Trainable params: 528,389\n",
            "Non-trainable params: 66,784\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9ATBdSRSx3z",
        "colab_type": "code",
        "outputId": "1b72f0e5-1907-4c01-f549-d6925e3a3e17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "test_accuracy_results = {}\n",
        "\n",
        "for n_examples_per_class in n_examples_per_class_list:\n",
        "  X_train_tgt_sample, y_train_tgt_sample = subsample_train_data(X_train_tgt[:-1000], y_train_tgt[:-1000], n_examples_per_class)\n",
        "  assert len(y_train_tgt_sample) <= n_examples_per_class * len(np.unique(y_train_tgt))\n",
        "  \n",
        "  X_train_tgt_cnn_sample, y_train_tgt_cnn_sample, label_map = preprocess_data_cnn_model(X_train_tgt_sample, y_train_tgt_sample)\n",
        "  X_valid_tgt_cnn, y_valid_tgt_cnn, label_map = preprocess_data_cnn_model(X_train_tgt[1000:], y_train_tgt[1000:], label_map)\n",
        "  X_test_tgt_cnn, y_test_tgt_cnn, label_map = preprocess_data_cnn_model(X_test_tgt, y_test_tgt, label_map)\n",
        "\n",
        "  model = create_fine_tune_cnn_model(\n",
        "    pre_trained_model,\n",
        "    num_classes=5,\n",
        "    fc_sizes=[512],\n",
        "    dropout_prob=0.2)\n",
        "  \n",
        "  gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n",
        "                         height_shift_range=0.08, zoom_range=0.08)\n",
        "  test_gen = ImageDataGenerator()\n",
        "\n",
        "  train_generator = gen.flow(X_train_tgt_cnn_sample, y_train_tgt_cnn_sample, batch_size=128)\n",
        "  test_generator = test_gen.flow(X_valid_tgt_cnn, y_valid_tgt_cnn, batch_size=128)\n",
        "\n",
        "  # checkpoint_path = \"cs231n/project/model_checkpoints/minist_fc_test/cp.ckpt\"\n",
        "  checkpoint_path = output_dir+\"mnist_cnn_tl_{}_samples_per_class/cp.ckpt\".format(n_examples_per_class)\n",
        "  checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "  # Create a callback that saves the model's weights\n",
        "  cp_callback = ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                verbose=1)\n",
        "  model.fit(train_generator, \n",
        "            steps_per_epoch=60000//128, \n",
        "            epochs=5, \n",
        "            verbose=1, \n",
        "            validation_data=test_generator,\n",
        "            validation_steps=10000//128,\n",
        "            callbacks=[cp_callback])\n",
        "  \n",
        "  score = model.evaluate(X_test_tgt_cnn, y_test_tgt_cnn)\n",
        "  print('+++++++++++++++++++++++++++++++++++')\n",
        "  print('num examples per class', n_examples_per_class)\n",
        "  print('Test score:', score[0])\n",
        "  print('Test accuracy:', score[1])\n",
        "  print('+++++++++++++++++++++++++++++++++++')\n",
        "  test_accuracy_results[n_examples_per_class] = score[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "467/468 [============================>.] - ETA: 0s - loss: 0.0071 - accuracy: 0.9979\n",
            "Epoch 00001: saving model to /content/gdrive/My Drive/cs231n_project/mnist_cnn_tl_1_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_cnn_tl_1_samples_per_class/cp.ckpt/assets\n",
            "468/468 [==============================] - 6s 13ms/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.9314 - val_accuracy: 0.7617\n",
            "Epoch 2/5\n",
            "461/468 [============================>.] - ETA: 0s - loss: 3.6314e-05 - accuracy: 1.0000\n",
            "Epoch 00002: saving model to /content/gdrive/My Drive/cs231n_project/mnist_cnn_tl_1_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_cnn_tl_1_samples_per_class/cp.ckpt/assets\n",
            "468/468 [==============================] - 7s 15ms/step - loss: 3.6395e-05 - accuracy: 1.0000 - val_loss: 0.9223 - val_accuracy: 0.7688\n",
            "Epoch 3/5\n",
            "461/468 [============================>.] - ETA: 0s - loss: 1.9401e-05 - accuracy: 1.0000\n",
            "Epoch 00003: saving model to /content/gdrive/My Drive/cs231n_project/mnist_cnn_tl_1_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_cnn_tl_1_samples_per_class/cp.ckpt/assets\n",
            "468/468 [==============================] - 6s 13ms/step - loss: 1.9242e-05 - accuracy: 1.0000 - val_loss: 0.9503 - val_accuracy: 0.7669\n",
            "Epoch 4/5\n",
            "465/468 [============================>.] - ETA: 0s - loss: 1.2378e-05 - accuracy: 1.0000\n",
            "Epoch 00004: saving model to /content/gdrive/My Drive/cs231n_project/mnist_cnn_tl_1_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_cnn_tl_1_samples_per_class/cp.ckpt/assets\n",
            "468/468 [==============================] - 6s 13ms/step - loss: 1.2493e-05 - accuracy: 1.0000 - val_loss: 0.9842 - val_accuracy: 0.7650\n",
            "Epoch 5/5\n",
            "466/468 [============================>.] - ETA: 0s - loss: 8.1913e-06 - accuracy: 1.0000\n",
            "Epoch 00005: saving model to /content/gdrive/My Drive/cs231n_project/mnist_cnn_tl_1_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_cnn_tl_1_samples_per_class/cp.ckpt/assets\n",
            "468/468 [==============================] - 6s 13ms/step - loss: 8.1705e-06 - accuracy: 1.0000 - val_loss: 0.9994 - val_accuracy: 0.7661\n",
            "152/152 [==============================] - 1s 4ms/step - loss: 0.9379 - accuracy: 0.7840\n",
            "+++++++++++++++++++++++++++++++++++\n",
            "num examples per class 1\n",
            "Test score: 0.9378764629364014\n",
            "Test accuracy: 0.7839950919151306\n",
            "+++++++++++++++++++++++++++++++++++\n",
            "Epoch 1/5\n",
            "468/468 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 0.9966\n",
            "Epoch 00001: saving model to /content/gdrive/My Drive/cs231n_project/mnist_cnn_tl_5_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_cnn_tl_5_samples_per_class/cp.ckpt/assets\n",
            "468/468 [==============================] - 10s 21ms/step - loss: 0.0106 - accuracy: 0.9966 - val_loss: 0.7703 - val_accuracy: 0.8098\n",
            "Epoch 2/5\n",
            "465/468 [============================>.] - ETA: 0s - loss: 1.4000e-04 - accuracy: 1.0000\n",
            "Epoch 00002: saving model to /content/gdrive/My Drive/cs231n_project/mnist_cnn_tl_5_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_cnn_tl_5_samples_per_class/cp.ckpt/assets\n",
            "468/468 [==============================] - 10s 21ms/step - loss: 1.3947e-04 - accuracy: 1.0000 - val_loss: 0.5363 - val_accuracy: 0.8600\n",
            "Epoch 3/5\n",
            "465/468 [============================>.] - ETA: 0s - loss: 6.0669e-05 - accuracy: 1.0000\n",
            "Epoch 00003: saving model to /content/gdrive/My Drive/cs231n_project/mnist_cnn_tl_5_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_cnn_tl_5_samples_per_class/cp.ckpt/assets\n",
            "468/468 [==============================] - 9s 20ms/step - loss: 6.0464e-05 - accuracy: 1.0000 - val_loss: 0.5163 - val_accuracy: 0.8649\n",
            "Epoch 4/5\n",
            "465/468 [============================>.] - ETA: 0s - loss: 3.1145e-05 - accuracy: 1.0000\n",
            "Epoch 00004: saving model to /content/gdrive/My Drive/cs231n_project/mnist_cnn_tl_5_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_cnn_tl_5_samples_per_class/cp.ckpt/assets\n",
            "468/468 [==============================] - 10s 20ms/step - loss: 3.1099e-05 - accuracy: 1.0000 - val_loss: 0.5213 - val_accuracy: 0.8650\n",
            "Epoch 5/5\n",
            "466/468 [============================>.] - ETA: 0s - loss: 2.3536e-05 - accuracy: 1.0000\n",
            "Epoch 00005: saving model to /content/gdrive/My Drive/cs231n_project/mnist_cnn_tl_5_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_cnn_tl_5_samples_per_class/cp.ckpt/assets\n",
            "468/468 [==============================] - 9s 20ms/step - loss: 2.3514e-05 - accuracy: 1.0000 - val_loss: 0.4979 - val_accuracy: 0.8724\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.4564 - accuracy: 0.8807\n",
            "+++++++++++++++++++++++++++++++++++\n",
            "num examples per class 5\n",
            "Test score: 0.45643436908721924\n",
            "Test accuracy: 0.8806830048561096\n",
            "+++++++++++++++++++++++++++++++++++\n",
            "Epoch 1/5\n",
            "466/468 [============================>.] - ETA: 0s - loss: 0.0101 - accuracy: 0.9968\n",
            "Epoch 00001: saving model to /content/gdrive/My Drive/cs231n_project/mnist_cnn_tl_10_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_cnn_tl_10_samples_per_class/cp.ckpt/assets\n",
            "468/468 [==============================] - 14s 30ms/step - loss: 0.0101 - accuracy: 0.9968 - val_loss: 0.2465 - val_accuracy: 0.9279\n",
            "Epoch 2/5\n",
            "468/468 [==============================] - ETA: 0s - loss: 1.5872e-04 - accuracy: 1.0000\n",
            "Epoch 00002: saving model to /content/gdrive/My Drive/cs231n_project/mnist_cnn_tl_10_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_cnn_tl_10_samples_per_class/cp.ckpt/assets\n",
            "468/468 [==============================] - 13s 28ms/step - loss: 1.5872e-04 - accuracy: 1.0000 - val_loss: 0.2390 - val_accuracy: 0.9293\n",
            "Epoch 3/5\n",
            "466/468 [============================>.] - ETA: 0s - loss: 6.9793e-05 - accuracy: 1.0000\n",
            "Epoch 00003: saving model to /content/gdrive/My Drive/cs231n_project/mnist_cnn_tl_10_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_cnn_tl_10_samples_per_class/cp.ckpt/assets\n",
            "468/468 [==============================] - 13s 27ms/step - loss: 6.9622e-05 - accuracy: 1.0000 - val_loss: 0.2359 - val_accuracy: 0.9336\n",
            "Epoch 4/5\n",
            "467/468 [============================>.] - ETA: 0s - loss: 3.8865e-05 - accuracy: 1.0000\n",
            "Epoch 00004: saving model to /content/gdrive/My Drive/cs231n_project/mnist_cnn_tl_10_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_cnn_tl_10_samples_per_class/cp.ckpt/assets\n",
            "468/468 [==============================] - 13s 28ms/step - loss: 3.8808e-05 - accuracy: 1.0000 - val_loss: 0.2266 - val_accuracy: 0.9393\n",
            "Epoch 5/5\n",
            "467/468 [============================>.] - ETA: 0s - loss: 2.5633e-05 - accuracy: 1.0000\n",
            "Epoch 00005: saving model to /content/gdrive/My Drive/cs231n_project/mnist_cnn_tl_10_samples_per_class/cp.ckpt\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/cs231n_project/mnist_cnn_tl_10_samples_per_class/cp.ckpt/assets\n",
            "468/468 [==============================] - 13s 27ms/step - loss: 2.5601e-05 - accuracy: 1.0000 - val_loss: 0.2715 - val_accuracy: 0.9249\n",
            "152/152 [==============================] - 1s 3ms/step - loss: 0.2289 - accuracy: 0.9321\n",
            "+++++++++++++++++++++++++++++++++++\n",
            "num examples per class 10\n",
            "Test score: 0.22894226014614105\n",
            "Test accuracy: 0.9321127533912659\n",
            "+++++++++++++++++++++++++++++++++++\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYv9Mbw_To1z",
        "colab_type": "code",
        "outputId": "b8fdb512-64cd-45dd-d8a5-6ad4ad53a080",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print_accuracy_results(test_accuracy_results)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num examples per class: accuracy\n",
            "1: 0.7840\n",
            "5: 0.8807\n",
            "10: 0.9321\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSjwUrN_VNIT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}